{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "arcoupling_linear_map: False\n",
      "beam_size: 5\n",
      "bsz: 16\n",
      "debug: False\n",
      "device: cuda\n",
      "embedding_size: 300\n",
      "flow_hidden: 300\n",
      "flow_k: 3\n",
      "flow_l: 8\n",
      "glove_path: ./data/glove.840B.300d.txt\n",
      "gpus: [0]\n",
      "idx2word_path: ./cache/idx2word.pickle\n",
      "input_streams: ['sub', 'vcpt']\n",
      "log_freq: 1000\n",
      "lr: 0.0003\n",
      "max_es_cnt: 3\n",
      "max_len: 16\n",
      "max_sub_l: 512\n",
      "max_vcpt_l: 512\n",
      "max_vid_l: 480\n",
      "multiscale: False\n",
      "n_epoch: 100\n",
      "n_layers_cls: 1\n",
      "no_core_driver: False\n",
      "no_glove: False\n",
      "no_normalize_v: False\n",
      "no_ts: False\n",
      "restore_name: None\n",
      "results_dir_base: results/results_\n",
      "return_beams: False\n",
      "save_name: test2\n",
      "share_weights: False\n",
      "squeeze_dim: 2\n",
      "test_bsz: 32\n",
      "test_path: ./data/tvqa_test_public_processed.json\n",
      "train_path: ./data/tvqa_train_processed.json\n",
      "trainable_paddings: False\n",
      "use_ar: True\n",
      "use_baseline: False\n",
      "use_recurrent: False\n",
      "use_transformer: False\n",
      "val_steps: 10\n",
      "valid_path: ./data/tvqa_val_processed.json\n",
      "vcpt_path: ./data/det_visual_concepts_hq.pickle\n",
      "vid_feat_path: ./data/tvqa_imagenet_pool5.h5\n",
      "vid_feat_size: 2048\n",
      "vocab_embedding_path: ./cache/vocab_embedding.pickle\n",
      "vocab_size: 0\n",
      "wd: 1e-05\n",
      "word2idx_path: ./cache/word2idx.pickle\n",
      "word_count_threshold: 2\n",
      "-------------- End ----------------\n",
      "\n",
      "Loading cache ...\n",
      "The number of parameters of model is 0.0 M\n",
      "The number of parameters of flow is 27.632196 M\n",
      "0it [00:00, ?it/s]reconstruction error: tensor(1.1120, device='cuda:0')\n",
      "tensor([25037, 22526, 20086, 18809,  5475, 22750,  9841, 15963, 37134, 36168,\n",
      "        31178,  1536, 12250,  1692,  3101], device='cuda:0') tensor([25037, 15602, 32030, 36648, 32282,  9823, 15602,  6392, 37134,  6263,\n",
      "        28214,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0], device='cuda:0')\n",
      " Train Epoch 0 loss 29.9767 nll-loss 29.9767 recon-loss 0.0000 Val loss 10.2104 nll-loss 10.2104 recon-loss 0.0000 logp -0.1971\n",
      "<sos> openings r44 backstage random prayer props banners gifs apparition tryin' castlefreak1212 callbacks chaz annulled saluted \n",
      "<sos> recess ramadan bug doody downtairs weinerburger cathed mooned beefjerky flashdances galloped warden congratulates relaunch ofwho \n",
      "<sos> teleport romore bug matrix rosary approves cystoplasty conclusive patang adviser auditioning candidates unrecognizable started commendations \n",
      "<sos> recess medak grads neighbors' shhh suspends nag microscissors ''this walken jesuses ethical advisor instruct swooped \n",
      "<sos> recess worded clipboard stripe exorcism authur greek studies psshoo during lambda callbacks collins' shoe assassinated \n",
      "1000it [08:51,  1.89it/s]reconstruction error: tensor(0.3189, device='cuda:0')\n",
      "tensor([25037, 15602, 32030, 36648, 32282,  9823, 15602,  6392, 37134,  6263,\n",
      "        28214,     2,     0,     0,     0], device='cuda:0') tensor([25037, 15602, 32030, 36648, 32282,  9823, 15602,  6392, 37134,  6263,\n",
      "        28214,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0], device='cuda:0')\n",
      " Train Epoch 0 loss -1729.8003 nll-loss -1729.8003 recon-loss 0.0000 Val loss -3695.1578 nll-loss -3695.1578 recon-loss 0.0000 logp -2.5133\n",
      "<sos> what s aside dialogue of voices <eos> 's about now' of 10 responses 'you <eos> \n",
      "<sos> what sake aside crainiotomy <eos> \n",
      "<sos> what argument aside ' bloopers hypothetical responses puffin' <eos> physicians patient heat explain 'you clarity \n",
      "<sos> what perpetual aside trivia of now' scenarios answer <eos> explanation recommend temperature explanations 'you comments \n",
      "<sos> what argument aside 15 3 reaches <eos> castlefreak1212 data of of <eos> say commented ? \n",
      "2000it [17:41,  2.00it/s]reconstruction error: tensor(2.2110e+09, device='cuda:0')\n",
      "----warning, invertibility_test failed----\n",
      "tensor([ 8577, 16132, 32251,  1392, 15173, 36596, 18236, 29370, 18255, 30151,\n",
      "         6181,  1054, 24008, 17781,  7120], device='cuda:0') tensor([25037, 15602, 32030, 36648, 32282,  9823, 15602,  6392, 37134,  6263,\n",
      "        28214,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0], device='cuda:0')\n",
      " Train Epoch 0 loss 1579737.6913 nll-loss 1579737.6913 recon-loss 0.0000 Val loss -4789.7947 nll-loss -4789.7947 recon-loss 0.0000 logp -7.4698\n",
      "<sos> dispenser 29 laborers levei gaydar sneezed commended agility roe concerned gretchen newport ids silencer commended \n",
      "<sos> paintball vacuum ab foster coyote commended weaklings gorshin goodfella appreciate woolery advances president levei ppth \n",
      "<sos> dead'' application investigative resident silencer herjob apprenticed involving 299 doctoring' sears volunteered merchant silencer chard \n",
      "<sos> vacuums explored apprenticed howls levei willebrand talkin' cocoon merchant chagas' separately apprenticed strap paintball specialist \n",
      "<sos> contestant 299 vote radiologist wiggin bicyclist saturday phoe chard herjob gorshin acupressure widened gut levei \n",
      "2673it [23:41,  1.94it/s]^C\n",
      "2673it [23:41,  1.88it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"main_flow.py\", line 261, in <module>\n",
      "    # train for one epoch, valid per n batches, save the log and the best model\n",
      "  File \"main_flow.py\", line 80, in train\n",
      "    log_p, logdet, flow_z, inputs = model.encode(flow, flow_inputs, inputs_length)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow_entry.py\", line 50, in encode\n",
      "    log_p, logdet, flow_z = flow(flow_inputs, inputs_length)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flowauto_eb4.py\", line 456, in forward\n",
      "    out, logdet_i = self.flows[i](out, input_length, all_embeddings)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flowauto_eb4.py\", line 374, in forward\n",
      "    out, det2 = self.coupling(out, input_length, embeddings=embeddings)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flowauto_eb4.py\", line 155, in forward\n",
      "    r_t, prev_states = self.flow_lstm_r(lstm_inputs, prev_states)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/rnn.py\", line 129, in forward\n",
      "    outputs, hidden = self.rnn(inputs, states)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\", line 661, in forward\n",
      "    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 -W ignore main_flow.py --input_streams sub vcpt --gpus 0 \\\n",
    "--bsz 16 --test_bsz 32 --val_step 10 --beam_size 5 --log_freq 1000\\\n",
    "--flow_hidden 300 --flow_l 8 --flow_k 3 --squeeze_dim 2\\\n",
    "--lr 3e-4  \\\n",
    "--use_ar --save_name test2\n",
    "# --trainable_paddings\n",
    "# --restore_name test2\n",
    "# --save_name L32_arflow_eb --restore_name L32_arflow_eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  2 09:20:09 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN X (Pascal)    On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 23%   25C    P8     9W / 250W |      4MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN X (Pascal)    On   | 00000000:04:00.0 Off |                  N/A |\n",
      "| 41%   69C    P2    96W / 250W |  11773MiB / 12196MiB |     19%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN X (Pascal)    On   | 00000000:83:00.0 Off |                  N/A |\n",
      "| 64%   86C    P2   209W / 250W |   3931MiB / 12196MiB |     82%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN X (Pascal)    On   | 00000000:84:00.0 Off |                  N/A |\n",
      "| 23%   29C    P8     8W / 250W |  11023MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A     30369      C   python3                         11769MiB |\n",
      "|    2   N/A  N/A     28381      C   python                           3925MiB |\n",
      "|    3   N/A  N/A     12221      C   python                          11019MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -W ignore main_flow.py --input_streams sub vcpt --gpus 2 \\\n",
    "--hsz1 150 --hsz2 150 --bsz 16 --test_bsz 32 --val_step 10 --max_sub_l 64 --max_vcpt_l 64 \\\n",
    "--flow_hidden 300 --log_freq 1000 --save_name test1  --use_transformer \\\n",
    "--flow_l 64 --flow_k 3  --squeeze_dim 2 --lr 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
