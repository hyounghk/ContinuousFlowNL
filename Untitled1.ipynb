{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "arcoupling_linear_map: False\n",
      "beam_size: 5\n",
      "bsz: 16\n",
      "debug: False\n",
      "device: cuda\n",
      "embedding_size: 300\n",
      "flow_hidden: 300\n",
      "flow_k: 3\n",
      "flow_l: 32\n",
      "glove_path: ./data/glove.840B.300d.txt\n",
      "gpus: [1]\n",
      "idx2word_path: ./cache/idx2word.pickle\n",
      "input_streams: ['sub', 'vcpt']\n",
      "log_freq: 1000\n",
      "lr: 0.0003\n",
      "max_es_cnt: 3\n",
      "max_len: 16\n",
      "max_sub_l: 512\n",
      "max_vcpt_l: 512\n",
      "max_vid_l: 480\n",
      "multiscale: False\n",
      "n_epoch: 100\n",
      "n_layers_cls: 1\n",
      "no_core_driver: False\n",
      "no_glove: False\n",
      "no_normalize_v: False\n",
      "no_ts: False\n",
      "restore_name: None\n",
      "results_dir_base: results/results_\n",
      "return_beams: False\n",
      "save_name: test1\n",
      "share_weights: False\n",
      "squeeze_dim: 2\n",
      "test_bsz: 32\n",
      "test_path: ./data/tvqa_test_public_processed.json\n",
      "train_path: ./data/tvqa_train_processed.json\n",
      "trainable_paddings: True\n",
      "use_ar: True\n",
      "use_baseline: False\n",
      "use_recurrent: False\n",
      "use_transformer: False\n",
      "val_steps: 10\n",
      "valid_path: ./data/tvqa_val_processed.json\n",
      "vcpt_path: ./data/det_visual_concepts_hq.pickle\n",
      "vid_feat_path: ./data/tvqa_imagenet_pool5.h5\n",
      "vid_feat_size: 2048\n",
      "vocab_embedding_path: ./cache/vocab_embedding.pickle\n",
      "vocab_size: 0\n",
      "wd: 1e-05\n",
      "word2idx_path: ./cache/word2idx.pickle\n",
      "word_count_threshold: 2\n",
      "-------------- End ----------------\n",
      "\n",
      "Loading cache ...\n",
      "The number of parameters of model is 0.0 M\n",
      "The number of parameters of flow is 94.586352 M\n",
      "0it [00:00, ?it/s]reconstruction error: tensor(336.2143, device='cuda:0')\n",
      "----warning, invertibility_test failed----\n",
      "tensor([25037, 31678,  5762, 26305,  3055,  8212,  5697, 12400, 36054, 29820,\n",
      "        27087, 29276,  4263,  4275,  3035], device='cuda:0') tensor([25037, 15602, 32030, 36648, 32282,  9823, 15602,  6392, 37134,  6263,\n",
      "        28214,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0], device='cuda:0')\n",
      " Train Epoch 0 loss 127.2737 nll-loss 127.2737 recon-loss 0.0000 Val loss 84.8893 nll-loss 84.8893 recon-loss 0.0000 logp -0.1703\n",
      "<sos> druther girifriends hatter ergo cf breaks monocle fyi unannounced fever hideout corday wagner chapter espositon \n",
      "<sos> swashbuckler gremlins osiris tipster disinfectant vf flennan bromstead overpowered o' teds edisons aztec stalked teds \n",
      "<sos> kl5 destroyer reexamine quixote phil cybill undilated zeus rodriquez feelin' zazzy bullied kiilled casper nickelodeon \n",
      "<sos> lewoits patched reaper seltzer tupperware showcase siegal hordichuk foaming bands espositon gophers orton hatter muchacho \n",
      "<sos> swashbuckler destroyer osiris wagner appre ''who strain tagged kubisak coochie steamier tetris zazzles kayacking brads \n",
      "1000it [34:09,  1.89s/it]reconstruction error: tensor(0.2998, device='cuda:0')\n",
      "tensor([25037, 15602, 32030, 36648, 32282,  9823, 15602,  6392, 37134,  6263,\n",
      "        28214,     2, 31978, 31978, 32834], device='cuda:0') tensor([25037, 15602, 32030, 36648, 32282,  9823, 15602,  6392, 37134,  6263,\n",
      "        28214,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0], device='cuda:0')\n",
      " Train Epoch 0 loss -1853.6851 nll-loss -1853.6851 recon-loss 0.0000 Val loss -3709.9032 nll-loss -3709.9032 recon-loss 0.0000 logp -8.7476\n",
      "<sos> that neil sheldon anyway curtis jamal bryan jamal allan stuart leonard bryan curtis alfred bryan \n",
      "<sos> that neil sheldon anyway curtis priya bryan jamal allan stuart leonard bryan curtis alfred bryan \n",
      "<sos> that neil sheldon anyway curtis jamal bryan jamal jamal richard leonard bryan curtis alfred bryan \n",
      "<sos> that neil sheldon anyway curtis jamal bryan jamal jamal richard leonard bryan curtis alfred bryan \n",
      "<sos> that neil sheldon anyway curtis steph bryan jamal allan stuart leonard bryan curtis alfred bryan \n",
      "1184it [40:27,  1.88s/it]^C\n",
      "1184it [40:27,  2.05s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"main_flow.py\", line 261, in <module>\n",
      "    cur_loss = train(opt, dset, model, flow, criterions, optimizer, epoch, best_loss, schedular, container1=save_numpy, container2=save_numpy_index, z_sample=z_sample, cos=cos)\n",
      "  File \"main_flow.py\", line 80, in train\n",
      "    log_p, logdet, flow_z, inputs = model.encode(flow, flow_inputs, inputs_length)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow_entry.py\", line 50, in encode\n",
      "    log_p, logdet, flow_z = flow(flow_inputs, inputs_length)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flowauto_eb4.py\", line 451, in forward\n",
      "    out, logdet_i = self.flows[i](out, input_length, all_embeddings)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flowauto_eb4.py\", line 369, in forward\n",
      "    out, det2 = self.coupling(out, input_length, embeddings=embeddings)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flowauto_eb4.py\", line 153, in forward\n",
      "    z_t, logdet_l = self.lstm_linear(r_t, c_t)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flowauto_eb4.py\", line 81, in forward\n",
      "    log, t = self.net(coup_a).chunk(2, 2)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 119, in forward\n",
      "    input = module(input)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 872, in _call_impl\n",
      "    for hook in itertools.chain(\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 -W ignore main_flow.py --input_streams sub vcpt --gpus 1 \\\n",
    "--bsz 16 --test_bsz 32 --val_step 10 --beam_size 5 --log_freq 1000\\\n",
    "--flow_hidden 300 --flow_l 32 --flow_k 3 --squeeze_dim 2\\\n",
    "--lr 3e-4 --trainable_paddings\\\n",
    "--use_ar --save_name test1\n",
    "# --restore_name test1\n",
    "# --restore_name L128_arflow_eb\n",
    "#  --arcoupling_linear_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug  3 17:53:08 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN X (Pascal)    On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 30%   55C    P2    73W / 250W |   3066MiB / 12196MiB |     34%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN X (Pascal)    On   | 00000000:04:00.0 Off |                  N/A |\n",
      "| 33%   59C    P0    86W / 250W |      4MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN X (Pascal)    On   | 00000000:83:00.0 Off |                  N/A |\n",
      "| 63%   87C    P2   184W / 250W |   5113MiB / 12196MiB |     86%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN X (Pascal)    On   | 00000000:84:00.0 Off |                  N/A |\n",
      "| 23%   29C    P8     8W / 250W |  11023MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2341      C   python3                          1511MiB |\n",
      "|    0   N/A  N/A     23507      C   python3                          1551MiB |\n",
      "|    2   N/A  N/A      2034      C   python                           5107MiB |\n",
      "|    3   N/A  N/A     12221      C   python                          11019MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "arcoupling_linear_map: False\n",
      "beam_size: 5\n",
      "bsz: 16\n",
      "debug: False\n",
      "device: cuda\n",
      "embedding_size: 300\n",
      "flow_hidden: 300\n",
      "flow_k: 3\n",
      "flow_l: 128\n",
      "glove_path: ./data/glove.840B.300d.txt\n",
      "gpus: [1]\n",
      "idx2word_path: ./cache/idx2word.pickle\n",
      "input_streams: ['sub', 'vcpt']\n",
      "log_freq: 1000\n",
      "lr: 1e-06\n",
      "max_es_cnt: 3\n",
      "max_len: 16\n",
      "max_sub_l: 512\n",
      "max_vcpt_l: 512\n",
      "max_vid_l: 480\n",
      "multiscale: False\n",
      "n_epoch: 100\n",
      "n_layers_cls: 1\n",
      "no_core_driver: False\n",
      "no_glove: False\n",
      "no_normalize_v: False\n",
      "no_ts: False\n",
      "restore_name: None\n",
      "results_dir_base: results/results_\n",
      "return_beams: False\n",
      "save_name: L256_K3_nonarflow\n",
      "share_weights: False\n",
      "squeeze_dim: 2\n",
      "test_bsz: 32\n",
      "test_path: ./data/tvqa_test_public_processed.json\n",
      "train_path: ./data/tvqa_train_processed.json\n",
      "trainable_paddings: False\n",
      "use_ar: False\n",
      "use_baseline: False\n",
      "use_recurrent: False\n",
      "use_transformer: True\n",
      "val_steps: 10\n",
      "valid_path: ./data/tvqa_val_processed.json\n",
      "vcpt_path: ./data/det_visual_concepts_hq.pickle\n",
      "vid_feat_path: ./data/tvqa_imagenet_pool5.h5\n",
      "vid_feat_size: 2048\n",
      "vocab_embedding_path: ./cache/vocab_embedding.pickle\n",
      "vocab_size: 0\n",
      "wd: 1e-05\n",
      "word2idx_path: ./cache/word2idx.pickle\n",
      "word_count_threshold: 2\n",
      "-------------- End ----------------\n",
      "\n",
      "Loading cache ...\n",
      "The number of parameters of model is 0.0 M\n",
      "The number of parameters of flow is 1041.2387 M\n",
      "0it [00:03, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"main_flow.py\", line 262, in <module>\n",
      "    cur_loss = train(opt, dset, model, flow, criterions, optimizer, epoch, best_loss, schedular, container1=save_numpy, container2=save_numpy_index, z_sample=z_sample, cos=cos)\n",
      "  File \"main_flow.py\", line 91, in train\n",
      "    optimizer[0].step()    \n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py\", line 89, in step\n",
      "    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 10.87 GiB already allocated; 3.00 MiB free; 11.15 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "!python3 -W ignore main_flow.py --input_streams sub vcpt --gpus 1 \\\n",
    "--bsz 16 --test_bsz 32 --val_step 10 \\\n",
    "--flow_hidden 300 --log_freq 1000 --save_name L256_K3_nonarflow --use_transformer \\\n",
    "--flow_l 128 --flow_k 3  --squeeze_dim 2 --lr 1e-6 \n",
    "# --restore_name L64_K3_nonarflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "arcoupling_linear_map: False\n",
      "bsz: 16\n",
      "debug: False\n",
      "device: cuda\n",
      "embedding_size: 300\n",
      "flow_hidden: 300\n",
      "flow_k: 3\n",
      "flow_l: 64\n",
      "glove_path: ./data/glove.840B.300d.txt\n",
      "gpus: [1]\n",
      "hsz1: 150\n",
      "hsz2: 150\n",
      "idx2word_path: ./cache/idx2word.pickle\n",
      "input_streams: ['sub', 'vcpt']\n",
      "log_freq: 1000\n",
      "lr: 0.0001\n",
      "max_es_cnt: 3\n",
      "max_len: 16\n",
      "max_sub_l: 64\n",
      "max_vcpt_l: 64\n",
      "max_vid_l: 480\n",
      "multiscale: False\n",
      "n_epoch: 100\n",
      "n_layers_cls: 1\n",
      "no_core_driver: False\n",
      "no_glove: False\n",
      "no_normalize_v: False\n",
      "no_ts: False\n",
      "restore_name: None\n",
      "results_dir_base: results/results_\n",
      "return_beams: False\n",
      "save_name: test1\n",
      "share_weights: False\n",
      "squeeze_dim: 2\n",
      "start_with_base: False\n",
      "test_bsz: 32\n",
      "test_path: ./data/tvqa_test_public_processed.json\n",
      "train_path: ./data/tvqa_train_processed.json\n",
      "trainable_paddings: False\n",
      "use_ar: False\n",
      "use_baseline: False\n",
      "use_recurrent: False\n",
      "use_transformer: True\n",
      "use_var: False\n",
      "val_steps: 10\n",
      "valid_path: ./data/tvqa_val_processed.json\n",
      "vcpt_path: ./data/det_visual_concepts_hq.pickle\n",
      "vid_feat_path: ./data/tvqa_imagenet_pool5.h5\n",
      "vid_feat_size: 2048\n",
      "vocab_embedding_path: ./cache/vocab_embedding.pickle\n",
      "vocab_size: 0\n",
      "wd: 1e-05\n",
      "word2idx_path: ./cache/word2idx.pickle\n",
      "word_count_threshold: 2\n",
      "-------------- End ----------------\n",
      "\n",
      "Loading cache ...\n",
      "The number of parameters of model is 0.0 M\n",
      "The number of parameters of flow is 521.1619 M\n",
      "0it [00:00, ?it/s]torch.Size([16])\n",
      "torch.Size([32])\n",
      "invertibility_test: tensor(3.6757e-07, device='cuda:0')\n",
      "tensor([    3, 25037, 15602, 32030, 36648, 32282,  9823, 15602,  6392, 37134,\n",
      "         6263, 28214,     2,     0,     0,     0], device='cuda:0') tensor([    3, 25037, 15602, 32030, 36648, 32282,  9823, 15602,  6392, 37134,\n",
      "         6263, 28214,     2,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0], device='cuda:0')\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "^C\n",
      "0it [00:06, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"main_flow.py\", line 265, in <module>\n",
      "    cur_loss = train(opt, dset, model, flow, criterions, optimizer, epoch, best_loss, schedular, container1=save_numpy, container2=save_numpy_index, z_sample=z_sample, cos=cos)\n",
      "  File \"main_flow.py\", line 103, in train\n",
      "    valid_loss, valid_nll_loss, valid_recon_loss, val_logp, sentenses = validate(opt, dset, model, flow, beam, mode=\"valid\", cos=cos)\n",
      "  File \"main_flow.py\", line 164, in validate\n",
      "    log_p, logdet, flow_z, inputs = model.encode(flow, flow_inputs, inputs_length)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow_entry.py\", line 55, in encode\n",
      "    log_p, logdet, flow_z = flow(flow_inputs, inputs_length)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flownonauto.py\", line 774, in forward\n",
      "    out, det, log_p, z_new = block(out, inputs_length)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flownonauto.py\", line 688, in forward\n",
      "    out, det = flow(out, inputs_length)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flownonauto.py\", line 638, in forward\n",
      "    out, det2 = self.coupling(out)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flownonauto.py\", line 585, in forward\n",
      "    temp = self.net(in_a)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 119, in forward\n",
      "    input = module(input)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flownonauto.py\", line 405, in forward\n",
      "    x = self.output_sublayer(x, self.feed_forward)\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flownonauto.py\", line 380, in forward\n",
      "    return x + sublayer(self.norm(x))\n",
      "  File \"/playpen10/terran/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/playpen10/terran/autoflow_git/model/flow/flownonauto.py\", line 289, in forward\n",
      "    return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 -W ignore main_flow.py --input_streams sub vcpt --gpus 1 \\\n",
    "--hsz1 150 --hsz2 150 --bsz 16 --test_bsz 32 --val_step 10 --max_sub_l 64 --max_vcpt_l 64 \\\n",
    "--flow_hidden 300 --log_freq 1000 --save_name test1 --use_transformer \\\n",
    "--flow_l 64 --flow_k 3  --squeeze_dim 2 --lr 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
